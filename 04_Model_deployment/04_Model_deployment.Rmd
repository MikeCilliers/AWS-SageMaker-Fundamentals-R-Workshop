---
title: "SageMaker fundamentals for R users - Part 04: Model deployment"
output: 
  html_notebook:
    theme: flatly
---

In the last module *Part 03: Hyperparameter tuning* we learned how to configure and start *a hyperparamter tuning job* using the built-in XGBoost algorithm. We started a tuning job to create 30 different XGBoost models based on the hotels data set. We identified and evaluated the best performing model. 

In this module we will deploy the best performing model as an HTTPS endpoint and make real-time predictions against it. You will learn the different steps of the SageMaker deployment process for *deploying a single model that is based on a built-in algorithm behind an endpoint*. We won't cover more sophisticated deployment options like endpoints with production variants or multi-model endpoints. Endpoints with production variants allow you to put heterogeneous models, which all serve the same purpose and reside in individual inference containers, behind the same endpoint. Multi-model endpoints allow you to deploy various homogeneous models of the same model type to a single SageMaker inference container which is behind a single endpoint.


## Introduction

We assume that you finished all previous workshop modules. In particular, we will deploy the tuned model that you created in the third module and use the test data set, you saved to your local disk in the second module, to make real-time predictions.

## The SageMaker deplyoment process

The deployment process is quite similar to the Bach Transform process you already used twice for generating batch inferences for the hold-out test set in the pervious two workshop modules. However, unlike Batch Transform a deployment process won't create a short-lived EC2 inference cluster but an inference cluster that is online until the user delibarately decides to shut it down. 


## Load necessary libraries

To use code in this module, you will need to load the following packages:

```{r message=FALSE, warning=FALSE}
library(reticulate)    # for calling the SageMaker Python SDK from R
library(purrr)         # for parsing the SageMaker responses
library(readr)         # for reading the test set from disk 
```


## Preparation

We activate the conda environment we prepared and set up in the first module *Part 01: Configuring RStudio* to connect to SageMaker from your RStudio environment. 

We import the SageMaker Python module and create a session object which provides convenient methods not just for training and tuning but also for model deployment.

```{r}
use_condaenv("sagemaker-r", required = TRUE)

sagemaker <- import("sagemaker")
session <- sagemaker$Session()
```









```{r}
region <- session$boto_region_name
```


## Model deployment 

Model deployment is a 3-step process 

> **Info**
> 
> An Estimator object specifies the core components for single training jobs that are part of a
> hyperparameter tuning job:
>
> 1) The type and the number of EC2 instance for the training job.
> 2) The location of the ML algorithm docker container image in the Elastic Container Registry.
> 3) The static hyperparameters that won't be tuned during the training job.
> 4) The learning objective.

Model deployment is a 3 step proc




### Step 1 - Create a model

Retrieve the model list using boto3. By default, the model list is ordered by descending creation time. 

```{r}
boto_client <- session$boto_session$client("sagemaker")
hotels_model_name <- boto_client$list_models()[["Models"]] %>% 
  map_chr("ModelName") %>% 
  .[[1]]

```



### Step 2 - Create endpoint configuration

* `name`:  Name of the Amazon SageMaker endpoint configuration to create.
* `model_name`: Name of the Amazon SageMaker Model.
* `initial_instance_count`: Minimum number of EC2 instances to launch. The actual number of active instances for an endpoint at any given time varies due to autoscaling.
* `instance_type`: Type of EC2 instance to launch


```{r}
config_name <- paste0(hotels_model_name, "-config")
session$create_endpoint_config(name = config_name,
                               model_name =  hotels_model_name, 
                               initial_instance_count = 1L, 
                               instance_type = "ml.m5.large")
```


* `endpoint_name`: Name of the Amazon SageMaker Endpoint being created.
* `config_name`: Name of the Amazon SageMaker endpoint configuration to deploy.
* `wait`: Whether to wait for the endpoint deployment to complete before returning.


### Step 3 - Create endpoint

```{r}
endpoint_name <- "hotels-endpoint"
session$create_endpoint(endpoint_name = endpoint_name, 
                        config_name = config_name,
                        wait = FALSE)
```


```{r}
boto_client$describe_endpoint(EndpointName = endpoint_name)[["EndpointStatus"]]
```

## Making real-time predictions against the endpoint

The Amazon SageMaker implementation of XGBoost supports CSV and libsvm formats for inference.
For CSV inference, the algorithm assumes that CSV input does not have the label column. 

```{r}
# The MIME type of the data sent to the inference endpoint.
csv_serializer <- sagemaker$serializers$CSVSerializer()
csv_serializer$CONTENT_TYPE <- "text/csv"

hotels_predictor <- sagemaker$predictor$Predictor(
  endpoint_name = "hotels-endpoint", 
  sagemaker_session = session, 
  serializer = csv_serializer)

```

```{r}
test_set <- read_csv("../data/hotels_test.csv", col_names = FALSE)

test_matrix <- test_set %>% 
  as.matrix()

predictions <- hotels_predictor$predict(data = test_matrix[1:5, ])
predictions
```


## Summary
